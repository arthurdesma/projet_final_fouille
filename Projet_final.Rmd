---
title: "Projet_final"
output: html_document
date: "2024-02-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Installer les packages nécessaires
# install.packages("readr")
# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("stringr")
# install.packages("tidytext")
# install.packages("tm")
# install.packages("text2vec")
# install.packages("Matrix")
# install.packages("tokenizers")
# install.packages("topicmodels")
# install.packages("pROC")
# install.packages("e1071")
# install.packages("caret")
# install.packages("MASS")
# install.packages("textstem")
# install.packages("ROSE")
# install.packages("quanteda")
# install.packages("quanteda.textstats")
# install.packages("stopwords")

# Chargement des packages nécessaires
library(readr)
library(dplyr)
library(ggplot2)
library(stringr)
library(tidytext)
library(tm)
library(text2vec)
library(Matrix)
library(tokenizers)
library(topicmodels)
library(pROC)
library(e1071)
library(caret)
library(MASS)
library(textstem)

# Suppression de toutes les variables en mémoire
rm(list = ls())
```

```{r}
# Chargement des fichiers csv
train_essays <- read_csv("llm-detect-ai-generated-text/train_essays.csv",show_col_types = FALSE)
train_prompts <- read_csv("llm-detect-ai-generated-text/train_prompts.csv",show_col_types = FALSE)
test_essays <- read_csv("llm-detect-ai-generated-text/test_essays.csv",show_col_types = FALSE)
sample_submission <- read_csv("llm-detect-ai-generated-text/sample_submission.csv",show_col_types = FALSE)
```

```{r}
# Vérifie les valeurs uniques de la colonne 'generated'
unique_values <- unique(train_essays$generated)
print(unique_values)

# Affiche le début du fichier train_essays
head(train_essays)
```

```{r}
# Résume le dataset train_essays
summary(train_essays)
```

```{r}
train_essays$length <- str_length(train_essays$text)
# Création de l'histogramme avec ggplot2
ggplot(train_essays, aes(x = length)) + 
  geom_histogram(bins = 30, fill = 'blue') +
  labs(title = "Distribution des longueurs des textes", x = "Longueur", y = "Fréquence")

# Suppression de la colonne 'length' du dataframe train_essays
train_essays$length <- NULL

```

```{r}
# Création histogramme de la Distribution des valeurs de la colonne 'generated'
train_essays %>% 
  count(generated) %>% 
  ggplot(aes(x = generated, y = n)) + 
  geom_bar(stat = "identity",fill = c("blue", "red"))+
  labs(title = "Distribution des valeurs de la colonne 'generated'", x = "Valeur de 'generated'", y = "Fréquence")
```

```{r}
# Première ligne de tes_essays
head(test_essays)
```

```{r}
# Résumé de test_essays
summary(test_essays)
```

```{r}
test_essays$length <- str_length(test_essays$text)
ggplot(test_essays, aes(x = length)) + geom_histogram(bins = 30,fill = 'blue')
test_essays$length <- NULL
```

```{r}
head(train_prompts)
```

```{r}
summary(train_prompts)
```

```{r}
train_prompts %>% 
  count(prompt_name) %>% 
  ggplot(aes(x = prompt_name, y = n)) + 
  geom_bar(stat = "identity",fill = c("blue", "red"))+
  labs(title = "Nombre d'occurrences par catégorie de prompt")
```

```{r}
head(sample_submission)
```

```{r}
summary(sample_submission)
```

```{r}

train_essays <- train_essays %>%
  mutate(number_of_sentences = str_count(text, "[.!?]"))
```

```{r}
calculer_longueur_moyenne_phrases <- function(texte) {
  # Sépare le texte en phrases
  phrases <- unlist(str_split(texte, "[.!?]"))
  
  # Supprime les espaces vides pour ne pas compter les "phrases" vides après la séparation
  phrases <- phrases[phrases != ""]
  
  # Calcule la longueur de chaque phrase
  longueurs <- nchar(trimws(phrases)) # `trimws` enlève les espaces blancs au début et à la fin
  
  # Retourne la longueur moyenne
  if (length(longueurs) > 0) {
    return(mean(longueurs))
  } else {
    return(NA) # si pas de phrase alors NA
  }
}

train_essays <- train_essays %>%
  mutate(longueur_moyenne_phrases = sapply(text, calculer_longueur_moyenne_phrases))

```

```{r}
library(quanteda)
library(quanteda.textstats)

# Création d'un corpus à partir de la colonne de texte
corpus_essays <- corpus(train_essays$text)

# Calcul des scores de lisibilité
readability_scores <- textstat_readability(corpus_essays, measure = "Flesch")

# Affichage des scores
print(readability_scores)

# Pour ajouter les scores au dataset original
train_essays$Flesch_Score_lisibilité <- readability_scores$Flesch

```

```{r}
# Nettoyage du texte
corpus_essays <- tokens(corpus_essays) %>%
  tokens_remove(pattern = stopwords("en"), padding = FALSE) %>%
  tokens_remove(pattern = "[\\p{P}\\p{N}]+", valuetype = "regex") %>%
  tokens_tolower() %>%
  tokens_ngrams(n = 2)

# Création d'une DFM
dfm_essays <- dfm(corpus_essays)

# Trouver les n-grammes les plus fréquents
top_ngrams <- topfeatures(dfm_essays, n = 10)

# Calcul du nombre total de n-grammes uniques par document
train_essays$ngrams_count <- ntoken(dfm_essays)
```

```{r}
library(quanteda)
# Création de tokens et calcul de TTR pour unigrammes (Diversité des n-grammes)
tokens_essays <- tokens(train_essays$text, what = "word")
dfm_essays <- dfm(tokens_essays)
train_essays$TTR <- ntype(dfm_essays) / ntoken(dfm_essays)
print(head(train_essays$TTR))
```

```{r}
library(quanteda)

bigrams_tokens <- tokens_ngrams(tokens_essays, n = 2)
dfm_bigrams <- dfm(bigrams_tokens)

# Identification des bigrammes les plus fréquents dans tout le corpus
top_bigrams <- names(top_ngrams)

# Calcul de la fréquence de chaque top bigramme dans chaque document
for (bigram in top_bigrams) {
  # Création d'un nom de colonne valide pour le dataframe
  col_name <- paste("freq", gsub(" ", "_", bigram), sep = "_")
  
  # Sélection du dfm_bigrams pour le bigramme actuel et somme des fréquences
  selected_dfm <- dfm_select(dfm_bigrams, pattern = bigram)
  
  # Ajout de la somme des fréquences du bigramme au dataframe
  train_essays[[col_name]] <- rowSums(as.matrix(selected_dfm))
}
```

```{r}
# Calcul des poids TF-IDF
tfidf <- dfm_tfidf(dfm_essays)

# Convertir la matrice TF-IDF en format matrice
tfidf_matrix <- as.matrix(tfidf)
# Affichage d'un extrait de la matrice TF-IDF
print(tfidf_matrix[1:5, 1:10])

```

Avant de réduire la dimensionnalité de l'espace, il faut d'abord préciser la nature de la relation : linéaire ou non linéaire afin d'utiliser l'approche convenable, pour se faire analysant la relation entre les différents features.

```{r}
library(ggplot2)

# Création d'un graphique de dispersion pour chaque paire de caractéristiques
ggplot(train_essays, aes(x = longueur_moyenne_phrases, y = Flesch_Score_lisibilité)) +
  geom_point() +
  labs(x = "Longueur moyenne des phrases", y = "Score de lisibilité de Flesch") +
  ggtitle("Longueur moyenne des phrases vs Score de lisibilité de Flesch")

ggplot(train_essays, aes(x = longueur_moyenne_phrases, y = TTR)) +
  geom_point() +
  labs(x = "Longueur moyenne des phrases", y = "TTR (Taux de Type-Token)") +
  ggtitle("Longueur moyenne des phrases vs TTR")

ggplot(train_essays, aes(x = Flesch_Score_lisibilité, y = TTR)) +
  geom_point() +
  labs(x = "Score de lisibilité de Flesch", y = "TTR (Taux de Type-Token)") +
  ggtitle("Score de lisibilité de Flesch vs TTR")


```

```{r}
# Extrait de la matrice de corrélation
correlation_matrix <- cor(train_essays[, c("longueur_moyenne_phrases", "Flesch_Score_lisibilité", "TTR")])

# Affichage des coefficients de corrélation individuels
print(correlation_matrix)
```

-La corrélation entre la 'longueur moyenne des phrases' et 'le score de lisibilité de Flesch' est faible à modérée et négative, indiquant qu'une augmentation de la longueur moyenne des phrases est généralement associée à une diminution du score de lisibilité de Flesch, et vice versa. Cependant, cette corrélation n'est pas très forte, ce qui suggère que d'autres facteurs peuvent également influencer cette relation. -Il y a une corrélation négative faible entre la 'longueur moyenne des phrases' et le 'TTR' , indiquant qu'une augmentation de la longueur moyenne des phrases est associée à une légère diminution du TTR, et vice versa. Cependant, cette corrélation n'est pas très forte. -Entre le 'score de lisibilité de Flesch' et le 'TTR', il n'y a pratiquement aucune corrélation linéaire. Cela indique que ces deux caractéristiques sont essentiellement indépendantes l'une de l'autre et que leur variation n'est pas liée de manière linéaire.

```{r}
# Calculer la matrice de corrélation
correlation_matrix <- cor(train_essays[, c("longueur_moyenne_phrases", "Flesch_Score_lisibilité", "TTR")])

# Visualiser la matrice de corrélation sous forme de heatmap
heatmap(correlation_matrix, 
        Colv = NA, Rowv = NA,
        col = colorRampPalette(c("blue", "white", "red"))(100),
        main = "Heatmap de la corrélation entre les caractéristiques")

```

La visualisation de la matrice de corrélation sous forme de heatmap confirme nos analyses par rapport à la relation entre les caractéristiques. En conclusion en peut dire que la relation entre les caractéristiques est non linéaires.

```{r}
library(kernlab)

X <- train_essays[, c("longueur_moyenne_phrases", "Flesch_Score_lisibilité", "TTR", paste0("freq_", top_bigrams))]

# Application de Kernel PCA
kpca_result <- kpca(~., data = as.data.frame(X), kernel = "rbfdot", features = 2)

# Extraction des composantes principales
X_kpca <- as.matrix(rotated(kpca_result))
```


```{r}
Y <- train_essays$generated

data <- data.frame(X_kpca, Generated = Y)

set.seed(2024)

# Créez une partition pour diviser les données en ensembles d'entraînement et de test
trainIndex <- createDataPartition(data$Generated, p = .8, 
                                  list = FALSE, 
                                  times = 1)

# Division les données en ensembles d'entraînement et de test
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Separation les caractéristiques et la variable cible dans les ensembles d'entraînement et de test
X_train <- trainData[, -ncol(trainData)]
Y_train <- trainData$Generated

X_test <- testData[, -ncol(testData)]
Y_test <- testData$Generated

# Entrainement du model
model_bayes <- naiveBayes(X_train, Y_train)

print(model_bayes)
```

```{r}
predictions <- predict(model_bayes, X_test)

# Convertion des prédictions et des vraies valeurs en facteurs
Y_test_factor <- factor(Y_test)
predictions_factor <- factor(predictions, levels = levels(Y_test_factor))

# Calcule de la matrice de confusion et les métriques
confMat <- confusionMatrix(predictions_factor, Y_test_factor)

# Extraction des métriques à partir de la matrice de confusion
accuracy <- confMat$overall['Accuracy']
precision <- confMat$byClass['Pos Pred Value']
recall <- confMat$byClass['Sensitivity']
f1_score <- 2 * (precision * recall) / (precision + recall)

# Affichage des métriques
cat("Précision :", accuracy, "\n")
cat("Précision (Pos Pred Value) :", precision, "\n")
cat("Rappel (Sensitivity) :", recall, "\n")
cat("Score F1 :", f1_score, "\n")
```